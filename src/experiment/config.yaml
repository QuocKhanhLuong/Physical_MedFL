# Federated Learning Experiment Configuration

# Experiment metadata
experiment:
  name: "medical_segmentation_fl"
  description: "Federated learning for medical image segmentation using ACDC dataset"
  version: "1.0.0"
  seed: 42

# Data configuration
data:
  dataset: "acdc"
  data_dir: "data/raw/ACDC"
  processed_dir: "data/processed"
  partitions_dir: "data/partitions"
  
  # Data preprocessing
  preprocessing:
    target_size: [256, 256]
    normalize: true
    clip_percentiles: [1, 99]
    apply_clahe: true
  
  # Data augmentation
  augmentation:
    rotation_range: 15.0
    zoom_range: 0.1
    horizontal_flip: true
    vertical_flip: false
    brightness_range: 0.1
    contrast_range: 0.1
    noise_std: 0.01

# Model configuration
model:
  type: "unet"  # Options: unet, kan, mlp
  n_channels: 1
  n_classes: 4
  dropout_rate: 0.1
  
  # Alternative configurations for different models
  # kan:
  #   input_size: 65536  # 256 * 256
  #   hidden_sizes: [128, 64]
  #   output_size: 4
  #   grid_size: 5
  #   spline_order: 3
  
  # mlp:
  #   input_size: 65536  # 256 * 256
  #   hidden_sizes: [512, 256, 128]
  #   output_size: 4
  #   dropout_rate: 0.1

# Federated learning configuration
federated:
  num_clients: 5
  num_rounds: 10
  min_fit_clients: 3
  min_evaluate_clients: 3
  min_available_clients: 3
  fraction_fit: 1.0
  fraction_evaluate: 1.0
  
  # Data partitioning
  partition_type: "iid"  # Options: iid, non_iid, pathological
  alpha: 0.5  # For non-IID Dirichlet distribution
  shards_per_client: 2  # For pathological partitioning
  
  # Client configuration
  client:
    max_train_samples: null  # null means use all available
    max_test_samples: 50
    train_test_split: 0.8

# Training configuration
training:
  batch_size: 8
  num_workers: 0
  pin_memory: true
  
  # Optimization
  optimizer: "adam"
  learning_rate: 0.001
  weight_decay: 0.0001
  
  # Learning rate scheduling
  scheduler:
    type: "step"  # Options: step, cosine, plateau
    step_size: 5
    gamma: 0.5
  
  # Loss function
  loss:
    type: "combined"  # Options: dice, focal, combined
    dice_weight: 0.5
    focal_weight: 0.5
    focal_alpha: 0.25
    focal_gamma: 2.0
  
  # Early stopping
  early_stopping:
    patience: 5
    min_delta: 0.001
    monitor: "val_dice"

# Evaluation configuration
evaluation:
  metrics: ["dice", "iou", "accuracy", "precision", "recall"]
  save_predictions: false
  visualize_results: false

# Logging configuration
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR
  log_dir: "logs"
  save_logs: true
  console_output: true

# Hardware configuration
hardware:
  device: "auto"  # Options: auto, cpu, cuda
  mixed_precision: false
  
# Paths and directories
paths:
  checkpoints_dir: "checkpoints"
  results_dir: "results"
  figures_dir: "figures"

# Reproducibility
reproducibility:
  deterministic: true
  benchmark: false 